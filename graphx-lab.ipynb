{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Graphs in Spark\n",
    "\n",
    "\n",
    "In this lab, you will learn some of the functionality of Spark GraphFrames. GraphFrames is the next-generation library for working with graphs on Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with GraphFrames in Python, you need to import the `graphframes` library. **Note, this library is not installed by default with Spark on EMR. The post-startup-script you ran today downloaded it and made it accessible to the Spark engine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be using data from the Bay Area Bike Share Portal (similar service to Capital Bikeshare in DC.) \n",
    "\n",
    "In the following two cells, read in two csv files located in s3:\n",
    "* `s3://bigdatateaching/bike-data/station_data.csv`\n",
    "* `s3://bigdatateaching/bike-data/trip_data.csv`\n",
    "\n",
    "The station file contains the metadata of the bicycile stations, and the trip data contains all the bike trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_stations = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_stations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now modify the two DataFrames read in above to create a vertix list and an edge list.\n",
    "\n",
    "In the next cell, use the station data and rename the \"name\" column to \"id\" and get distinct records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_vertices = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, use the trip data and rename the \"Start Station\" column to \"src\" and the \"End Station\" columnt to \"dst\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_edges = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, you will create a GraphFrame passing in a vertex list and an edge list. Which is which from your original datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_graph = GraphFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you will be using the GraphFrame more than once, it is best to cache it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_graph.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of vertices in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of edges in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the Graph\n",
    "\n",
    "The most basic way of interacting with the graph is querying it. Since the GraphFrame is based on DataFrames, you can perform the same type of operations you would on a DataFrame.\n",
    "\n",
    "In the next cell, show the top 10 source and destination combinations, ordered in descending order by count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "station_graph.edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, show the top 10 source and destination combinations **where the source or destination station is 'Townsend at 7th'**, ordered in descending order by count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_graph.edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting a Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you need to work with a subset of a graph. The easiest way to create a subset is create a new graph with the vertices and edges of your your subset. \n",
    "\n",
    "In the next cell, subset the edges where the source or destination station is 'Townsend at 7th', and create a new graph called sg1 using the original vertices and the new edge list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "townsend_and_7th_edges = \n",
    "sg1 = GraphFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motifs\n",
    "\n",
    "*Motifs* are ways of expressing structural patterns in a graph. The following cell creates a triangular pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = station_graph.find(\"(a)-[ab]->(b); (b)-[bc]->(c); (c)-[ca]->(a)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell takes the motifs DataFrame  and unnests the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "motifs.selectExpr(\"*\",\n",
    "    \"to_timestamp(ab.`Start Date`, 'MM/dd/yyyy HH:mm') as abStart\",\n",
    "    \"to_timestamp(bc.`Start Date`, 'MM/dd/yyyy HH:mm') as bcStart\",\n",
    "    \"to_timestamp(ca.`Start Date`, 'MM/dd/yyyy HH:mm') as caStart\")\\\n",
    "  .where(\"ca.`Bike #` = bc.`Bike #`\").where(\"ab.`Bike #` = bc.`Bike #`\")\\\n",
    "  .where(\"a.id != b.id\").where(\"b.id != c.id\")\\\n",
    "  .where(\"abStart < bcStart\").where(\"bcStart < caStart\")\\\n",
    "  .orderBy(expr(\"cast(caStart as long) - cast(abStart as long)\"))\\\n",
    "  .selectExpr(\"a.id\", \"b.id\", \"c.id\", \"ab.`Start Date`\", \"ca.`End Date`\")\\\n",
    ".limit(1).show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = station_graph.pageRank(resetProbability=0.15, maxIter=10)\n",
    "ranks.vertices.orderBy(desc(\"pagerank\")).select(\"id\", \"pagerank\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Degree and Out-Degree Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inDeg = station_graph.inDegrees\n",
    "inDeg.orderBy(desc(\"inDegree\")).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDeg = station_graph.outDegrees\n",
    "outDeg.orderBy(desc(\"outDegree\")).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degreeRatio = inDeg.join(outDeg, \"id\")\\\n",
    "  .selectExpr(\"id\", \"double(inDegree)/double(outDegree) as degreeRatio\")\n",
    "degreeRatio.orderBy(desc(\"degreeRatio\")).show(10, False)\n",
    "degreeRatio.orderBy(\"degreeRatio\").show(10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
